{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDKit: https://www.rdkit.org/\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, Descriptors, MACCSkeys\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "# Pandas: https://pandas.pydata.org\n",
    "import pandas as pd\n",
    "\n",
    "# NumPy: https://numpy.org/doc/stable/release.html\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn: https://scikit-learn.org\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV, StratifiedKFold, \n",
    "                                     RandomizedSearchCV)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, \n",
    "                             roc_curve, roc_auc_score)\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# XGBoost: https://xgboost.ai/\n",
    "import xgboost as xgb\n",
    "\n",
    "# SHAP: https://github.com/slundberg/shap\n",
    "import shap\n",
    "\n",
    "# XSmiles: https://github.com/mahmoudnafifi/xsmiles\n",
    "import xsmiles\n",
    "\n",
    "# JSON: https://docs.python.org/3/library/json.html\n",
    "import json\n",
    "\n",
    "# Matplotlib: https://matplotlib.org/\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SciPy: https://www.scipy.org/\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'udataset.xlsx'\n",
    "#file_path = \"new.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Substance</th>\n",
       "      <th>Substance_lower</th>\n",
       "      <th>CAS_number</th>\n",
       "      <th>Smiles_code</th>\n",
       "      <th>Additional info</th>\n",
       "      <th>Irritation</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heptanal</td>\n",
       "      <td>heptanal</td>\n",
       "      <td>111-71-7</td>\n",
       "      <td>CCCCCCC=O</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>Lukáš - 2006 Howard Maibach paper.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lilestralis/lilial</td>\n",
       "      <td>lilestralis/lilial</td>\n",
       "      <td>80-54-6</td>\n",
       "      <td>CC(CC1=CC=C(C=C1)C(C)(C)C)C=O</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-Bromopentane</td>\n",
       "      <td>1-bromopentane</td>\n",
       "      <td>110-53-2</td>\n",
       "      <td>CCCCCBr</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dl-Citronellol</td>\n",
       "      <td>dl-citronellol</td>\n",
       "      <td>106-22-9</td>\n",
       "      <td>CC(CCC=C(C)C)CCO</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d-Limonene</td>\n",
       "      <td>d-limonene</td>\n",
       "      <td>5989-27-5</td>\n",
       "      <td>CC1=CCC(CC1)C(=C)C</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Substance     Substance_lower CAS_number  \\\n",
       "0            Heptanal            heptanal   111-71-7   \n",
       "1  Lilestralis/lilial  lilestralis/lilial    80-54-6   \n",
       "2      1-Bromopentane      1-bromopentane   110-53-2   \n",
       "3      dl-Citronellol      dl-citronellol   106-22-9   \n",
       "4          d-Limonene          d-limonene  5989-27-5   \n",
       "\n",
       "                     Smiles_code Additional info Irritation  \\\n",
       "0                      CCCCCCC=O               -          I   \n",
       "1  CC(CC1=CC=C(C=C1)C(C)(C)C)C=O               -          I   \n",
       "2                        CCCCCBr               -          I   \n",
       "3               CC(CCC=C(C)C)CCO               -          I   \n",
       "4             CC1=CCC(CC1)C(=C)C               -          I   \n",
       "\n",
       "                                  Source  \n",
       "0  Lukáš - 2006 Howard Maibach paper.pdf  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                                    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptor calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_descriptors(df):\n",
    "    # List to hold descriptor data for each row\n",
    "    descriptor_data = []\n",
    "    \n",
    "    for smiles in df['Smiles_code']:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            # Append a dictionary of None values for all descriptors if SMILES is invalid\n",
    "            descriptor_data.append({desc[0]: None for desc in Descriptors.descList})\n",
    "            continue\n",
    "        \n",
    "        descriptors = {}\n",
    "        for descriptor, function in Descriptors.descList:\n",
    "            try:\n",
    "                descriptors[descriptor] = function(mol)\n",
    "            except Exception:\n",
    "                descriptors[descriptor] = None\n",
    "        \n",
    "        descriptor_data.append(descriptors)\n",
    "    \n",
    "    # Create a DataFrame for descriptor values with the same index as the original DataFrame\n",
    "    descriptors_df = pd.DataFrame(descriptor_data, index=df.index)\n",
    "    \n",
    "    # Concatenate original DataFrame with descriptor DataFrame\n",
    "    df = pd.concat([df, descriptors_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate fingerprint descriptors for each row\n",
    "def calculate_fingerprint(df, radius=2, n_bits=1024):\n",
    "    # List to hold fingerprint data for each row\n",
    "    fingerprint_data = []\n",
    "    \n",
    "    for smiles in df['Smiles_code']:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            fingerprint_data.append([None] * n_bits)  # Append None for invalid SMILES\n",
    "            continue\n",
    "        \n",
    "        # Calculate the Morgan fingerprint (radius 2, 1024 bits by default)\n",
    "        fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "        \n",
    "        # Convert fingerprint to a list of bits\n",
    "        fingerprint_data.append(list(fingerprint))\n",
    "    \n",
    "    # Create a DataFrame for fingerprint values\n",
    "    fingerprint_df = pd.DataFrame(fingerprint_data, columns=[f'Bit_{i}' for i in range(n_bits)])\n",
    "    \n",
    "    # Concatenate original dataframe with fingerprint dataframe\n",
    "    df = pd.concat([df, fingerprint_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:23:20] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:23:20] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:23:20] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "df = calculate_descriptors(df)\n",
    "#df = calculate_fingerprint(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Substance</th>\n",
       "      <th>Substance_lower</th>\n",
       "      <th>CAS_number</th>\n",
       "      <th>Smiles_code</th>\n",
       "      <th>Additional info</th>\n",
       "      <th>Irritation</th>\n",
       "      <th>Source</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heptanal</td>\n",
       "      <td>heptanal</td>\n",
       "      <td>111-71-7</td>\n",
       "      <td>CCCCCCC=O</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>Lukáš - 2006 Howard Maibach paper.pdf</td>\n",
       "      <td>9.768009</td>\n",
       "      <td>9.768009</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lilestralis/lilial</td>\n",
       "      <td>lilestralis/lilial</td>\n",
       "      <td>80-54-6</td>\n",
       "      <td>CC(CC1=CC=C(C=C1)C(C)(C)C)C=O</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.535393</td>\n",
       "      <td>10.535393</td>\n",
       "      <td>0.116191</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-Bromopentane</td>\n",
       "      <td>1-bromopentane</td>\n",
       "      <td>110-53-2</td>\n",
       "      <td>CCCCCBr</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.350347</td>\n",
       "      <td>3.350347</td>\n",
       "      <td>1.167500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dl-Citronellol</td>\n",
       "      <td>dl-citronellol</td>\n",
       "      <td>106-22-9</td>\n",
       "      <td>CC(CCC=C(C)C)CCO</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.629773</td>\n",
       "      <td>8.629773</td>\n",
       "      <td>0.329353</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d-Limonene</td>\n",
       "      <td>d-limonene</td>\n",
       "      <td>5989-27-5</td>\n",
       "      <td>CC1=CCC(CC1)C(=C)C</td>\n",
       "      <td>-</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.974575</td>\n",
       "      <td>3.974575</td>\n",
       "      <td>0.767315</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Substance     Substance_lower CAS_number  \\\n",
       "0            Heptanal            heptanal   111-71-7   \n",
       "1  Lilestralis/lilial  lilestralis/lilial    80-54-6   \n",
       "2      1-Bromopentane      1-bromopentane   110-53-2   \n",
       "3      dl-Citronellol      dl-citronellol   106-22-9   \n",
       "4          d-Limonene          d-limonene  5989-27-5   \n",
       "\n",
       "                     Smiles_code Additional info Irritation  \\\n",
       "0                      CCCCCCC=O               -          I   \n",
       "1  CC(CC1=CC=C(C=C1)C(C)(C)C)C=O               -          I   \n",
       "2                        CCCCCBr               -          I   \n",
       "3               CC(CCC=C(C)C)CCO               -          I   \n",
       "4             CC1=CCC(CC1)C(=C)C               -          I   \n",
       "\n",
       "                                  Source  MaxAbsEStateIndex  MaxEStateIndex  \\\n",
       "0  Lukáš - 2006 Howard Maibach paper.pdf           9.768009        9.768009   \n",
       "1                                    NaN          10.535393       10.535393   \n",
       "2                                    NaN           3.350347        3.350347   \n",
       "3                                    NaN           8.629773        8.629773   \n",
       "4                                    NaN           3.974575        3.974575   \n",
       "\n",
       "   MinAbsEStateIndex  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0           0.750000  ...           0             0           0   \n",
       "1           0.116191  ...           0             0           0   \n",
       "2           1.167500  ...           0             0           0   \n",
       "3           0.329353  ...           0             0           0   \n",
       "4           0.767315  ...           0             0           0   \n",
       "\n",
       "   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                  0             0            0            0             0   \n",
       "1                  0             0            0            0             0   \n",
       "2                  0             0            0            0             0   \n",
       "3                  0             0            0            0             0   \n",
       "4                  0             0            0            0             0   \n",
       "\n",
       "   fr_unbrch_alkane  fr_urea  \n",
       "0                 3        0  \n",
       "1                 0        0  \n",
       "2                 1        0  \n",
       "3                 0        0  \n",
       "4                 0        0  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Irritation</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>9.768009</td>\n",
       "      <td>9.768009</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.395123</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>114.188</td>\n",
       "      <td>100.076</td>\n",
       "      <td>114.104465</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>10.535393</td>\n",
       "      <td>10.535393</td>\n",
       "      <td>0.116191</td>\n",
       "      <td>0.116191</td>\n",
       "      <td>0.689906</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>204.313</td>\n",
       "      <td>184.153</td>\n",
       "      <td>204.151415</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>3.350347</td>\n",
       "      <td>3.350347</td>\n",
       "      <td>1.167500</td>\n",
       "      <td>1.167500</td>\n",
       "      <td>0.429137</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>151.047</td>\n",
       "      <td>139.959</td>\n",
       "      <td>150.004412</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>8.629773</td>\n",
       "      <td>8.629773</td>\n",
       "      <td>0.329353</td>\n",
       "      <td>0.329353</td>\n",
       "      <td>0.606746</td>\n",
       "      <td>12.727273</td>\n",
       "      <td>156.269</td>\n",
       "      <td>136.109</td>\n",
       "      <td>156.151415</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>3.974575</td>\n",
       "      <td>3.974575</td>\n",
       "      <td>0.767315</td>\n",
       "      <td>0.767315</td>\n",
       "      <td>0.485034</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>136.238</td>\n",
       "      <td>120.110</td>\n",
       "      <td>136.125201</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Irritation  MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  \\\n",
       "0          I           9.768009        9.768009           0.750000   \n",
       "1          I          10.535393       10.535393           0.116191   \n",
       "2          I           3.350347        3.350347           1.167500   \n",
       "3          I           8.629773        8.629773           0.329353   \n",
       "4          I           3.974575        3.974575           0.767315   \n",
       "\n",
       "   MinEStateIndex       qed        SPS    MolWt  HeavyAtomMolWt  ExactMolWt  \\\n",
       "0        0.750000  0.395123   9.125000  114.188         100.076  114.104465   \n",
       "1        0.116191  0.689906  13.600000  204.313         184.153  204.151415   \n",
       "2        1.167500  0.429137   9.000000  151.047         139.959  150.004412   \n",
       "3        0.329353  0.606746  12.727273  156.269         136.109  156.151415   \n",
       "4        0.767315  0.485034  25.800000  136.238         120.110  136.125201   \n",
       "\n",
       "   ...  fr_sulfide  fr_sulfonamd  fr_sulfone  fr_term_acetylene  fr_tetrazole  \\\n",
       "0  ...           0             0           0                  0             0   \n",
       "1  ...           0             0           0                  0             0   \n",
       "2  ...           0             0           0                  0             0   \n",
       "3  ...           0             0           0                  0             0   \n",
       "4  ...           0             0           0                  0             0   \n",
       "\n",
       "   fr_thiazole  fr_thiocyan  fr_thiophene  fr_unbrch_alkane  fr_urea  \n",
       "0            0            0             0                 3        0  \n",
       "1            0            0             0                 0        0  \n",
       "2            0            0             0                 1        0  \n",
       "3            0            0             0                 0        0  \n",
       "4            0            0             0                 0        0  \n",
       "\n",
       "[5 rows x 211 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = [\"Substance\", \"Substance_lower\", \"CAS_number\", \"Smiles_code\", \"Additional info\", \"Source\"]\n",
    "\n",
    "# Drop the columns using the drop() method with axis=1 (columns)\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     NaN Count  NaN Percentage\n",
      "MaxPartialCharge             4        0.896861\n",
      "MinPartialCharge             4        0.896861\n",
      "MaxAbsPartialCharge          4        0.896861\n",
      "MinAbsPartialCharge          4        0.896861\n",
      "BCUT2D_MWHI                 35        7.847534\n",
      "BCUT2D_MWLOW                35        7.847534\n",
      "BCUT2D_CHGHI                35        7.847534\n",
      "BCUT2D_CHGLO                35        7.847534\n",
      "BCUT2D_LOGPHI               35        7.847534\n",
      "BCUT2D_LOGPLOW              35        7.847534\n",
      "BCUT2D_MRHI                 35        7.847534\n",
      "BCUT2D_MRLOW                35        7.847534\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(df)\n",
    "nan_columns = df.columns[df.isnull().any()].tolist()\n",
    "nan_info = df[nan_columns].isnull().sum()\n",
    "nan_percentage = (nan_info / total_rows) * 100\n",
    "nan_info = pd.DataFrame({'NaN Count': nan_info, 'NaN Percentage': nan_percentage})\n",
    "print(nan_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"BCUT2D_MWHI\", \"BCUT2D_MWLOW\", \"BCUT2D_CHGHI\", \"BCUT2D_CHGLO\", \"BCUT2D_LOGPHI\", \"BCUT2D_LOGPLOW\", \"BCUT2D_MRHI\", \"BCUT2D_MRLOW\"]\n",
    "\n",
    "# Drop the columns using the drop() method with axis=1 (columns)\n",
    "df = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of zeros for each column\n",
    "zero_percentage = (df.isin([0]).sum() / len(df)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = zero_percentage[zero_percentage <= 90].index\n",
    "df = df[columns_to_keep]\n",
    "len(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    columns_to_drop = [\"Substance\", \"Substance_lower\", \"CAS_number\", \"Smiles_code\", \"Additional info\", \"Source\"]\n",
    "\n",
    "    #   Drop the columns using the drop() method with axis=1 (columns)\n",
    "    df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    columns_to_drop = [\"BCUT2D_MWHI\", \"BCUT2D_MWLOW\", \"BCUT2D_CHGHI\", \"BCUT2D_CHGLO\", \"BCUT2D_LOGPHI\", \"BCUT2D_LOGPLOW\", \"BCUT2D_MRHI\", \"BCUT2D_MRLOW\"]\n",
    "\n",
    "    # Drop the columns using the drop() method with axis=1 (columns)\n",
    "    df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    # Calculate the percentage of zeros for each column\n",
    "    zero_percentage = (df.isin([0]).sum() / len(df)) * 100\n",
    "    columns_to_keep = zero_percentage[zero_percentage <= 90].index\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 4\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows before dropping NaN values\n",
    "num_rows_before = df.shape[0]\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Count the number of rows after dropping NaN values\n",
    "num_rows_after = df.shape[0]\n",
    "\n",
    "# Calculate the number of rows dropped\n",
    "num_rows_dropped = num_rows_before - num_rows_after\n",
    "\n",
    "print(\"Number of rows dropped:\", num_rows_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df):\n",
    "    if isinstance(df, np.ndarray):\n",
    "        df = pd.DataFrame(df)\n",
    "    # Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "\n",
    "    # Calculate the interquartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    outlier_mask = (df < lower_bound) | (df > upper_bound)\n",
    "    \n",
    "    # Replace outliers with median\n",
    "    median_values = df.median(axis=1)\n",
    "    df = df.where(~outlier_mask, median_values, axis=0)\n",
    "\n",
    "\n",
    "    outliers = df[outlier_mask.any(axis=1)]\n",
    "    num_outliers = outliers.shape[0]\n",
    "    print(f\"Number of outliers detected: {num_outliers}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n4/lx5wz8kj2r79g9p8wxdnqk580000gn/T/ipykernel_92525/744444035.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Irritation'] = df['Irritation'].replace({'I': 1, 'NI': 0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Irritation</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_amide</th>\n",
       "      <th>fr_aniline</th>\n",
       "      <th>fr_aryl_methyl</th>\n",
       "      <th>fr_benzene</th>\n",
       "      <th>fr_ester</th>\n",
       "      <th>fr_ether</th>\n",
       "      <th>fr_halogen</th>\n",
       "      <th>fr_methoxy</th>\n",
       "      <th>fr_para_hydroxylation</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9.768009</td>\n",
       "      <td>9.768009</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.395123</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>114.188</td>\n",
       "      <td>100.076</td>\n",
       "      <td>114.104465</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.535393</td>\n",
       "      <td>10.535393</td>\n",
       "      <td>0.116191</td>\n",
       "      <td>0.116191</td>\n",
       "      <td>0.689906</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>204.313</td>\n",
       "      <td>184.153</td>\n",
       "      <td>204.151415</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.350347</td>\n",
       "      <td>3.350347</td>\n",
       "      <td>1.167500</td>\n",
       "      <td>1.167500</td>\n",
       "      <td>0.429137</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>151.047</td>\n",
       "      <td>139.959</td>\n",
       "      <td>150.004412</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8.629773</td>\n",
       "      <td>8.629773</td>\n",
       "      <td>0.329353</td>\n",
       "      <td>0.329353</td>\n",
       "      <td>0.606746</td>\n",
       "      <td>12.727273</td>\n",
       "      <td>156.269</td>\n",
       "      <td>136.109</td>\n",
       "      <td>156.151415</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.974575</td>\n",
       "      <td>3.974575</td>\n",
       "      <td>0.767315</td>\n",
       "      <td>0.767315</td>\n",
       "      <td>0.485034</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>136.238</td>\n",
       "      <td>120.110</td>\n",
       "      <td>136.125201</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Irritation  MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  \\\n",
       "0           1           9.768009        9.768009           0.750000   \n",
       "1           1          10.535393       10.535393           0.116191   \n",
       "2           1           3.350347        3.350347           1.167500   \n",
       "3           1           8.629773        8.629773           0.329353   \n",
       "4           1           3.974575        3.974575           0.767315   \n",
       "\n",
       "   MinEStateIndex       qed        SPS    MolWt  HeavyAtomMolWt  ExactMolWt  \\\n",
       "0        0.750000  0.395123   9.125000  114.188         100.076  114.104465   \n",
       "1        0.116191  0.689906  13.600000  204.313         184.153  204.151415   \n",
       "2        1.167500  0.429137   9.000000  151.047         139.959  150.004412   \n",
       "3        0.329353  0.606746  12.727273  156.269         136.109  156.151415   \n",
       "4        0.767315  0.485034  25.800000  136.238         120.110  136.125201   \n",
       "\n",
       "   ...  fr_amide  fr_aniline  fr_aryl_methyl  fr_benzene  fr_ester  fr_ether  \\\n",
       "0  ...         0           0               0           0         0         0   \n",
       "1  ...         0           0               0           1         0         0   \n",
       "2  ...         0           0               0           0         0         0   \n",
       "3  ...         0           0               0           0         0         0   \n",
       "4  ...         0           0               0           0         0         0   \n",
       "\n",
       "   fr_halogen  fr_methoxy  fr_para_hydroxylation  fr_unbrch_alkane  \n",
       "0           0           0                      0                 3  \n",
       "1           0           0                      0                 0  \n",
       "2           1           0                      0                 1  \n",
       "3           0           0                      0                 0  \n",
       "4           0           0                      0                 0  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Irritation'] = df['Irritation'].replace({'I': 1, 'NI': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers detected: 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n4/lx5wz8kj2r79g9p8wxdnqk580000gn/T/ipykernel_92525/1934217254.py:20: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.where(~outlier_mask, median_values, axis=0)\n"
     ]
    }
   ],
   "source": [
    "df = detect_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Irritation</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_amide</th>\n",
       "      <th>fr_aniline</th>\n",
       "      <th>fr_aryl_methyl</th>\n",
       "      <th>fr_benzene</th>\n",
       "      <th>fr_ester</th>\n",
       "      <th>fr_ether</th>\n",
       "      <th>fr_halogen</th>\n",
       "      <th>fr_methoxy</th>\n",
       "      <th>fr_para_hydroxylation</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648191</td>\n",
       "      <td>0.648191</td>\n",
       "      <td>0.790665</td>\n",
       "      <td>0.484550</td>\n",
       "      <td>0.378529</td>\n",
       "      <td>0.466241</td>\n",
       "      <td>0.205457</td>\n",
       "      <td>0.174775</td>\n",
       "      <td>0.206167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.699113</td>\n",
       "      <td>0.699113</td>\n",
       "      <td>0.122491</td>\n",
       "      <td>0.417018</td>\n",
       "      <td>0.713980</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.371992</td>\n",
       "      <td>0.330948</td>\n",
       "      <td>0.373260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529035</td>\n",
       "      <td>0.417235</td>\n",
       "      <td>0.459854</td>\n",
       "      <td>0.273566</td>\n",
       "      <td>0.248858</td>\n",
       "      <td>0.272784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572659</td>\n",
       "      <td>0.572659</td>\n",
       "      <td>0.347211</td>\n",
       "      <td>0.439730</td>\n",
       "      <td>0.619348</td>\n",
       "      <td>0.650299</td>\n",
       "      <td>0.283215</td>\n",
       "      <td>0.241706</td>\n",
       "      <td>0.284191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263747</td>\n",
       "      <td>0.263747</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.486395</td>\n",
       "      <td>0.480844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246201</td>\n",
       "      <td>0.211988</td>\n",
       "      <td>0.247030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Irritation  MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  \\\n",
       "0         1.0           0.648191        0.648191           0.790665   \n",
       "1         1.0           0.699113        0.699113           0.122491   \n",
       "2         1.0           0.000000        0.000000           0.000000   \n",
       "3         1.0           0.572659        0.572659           0.347211   \n",
       "4         1.0           0.263747        0.263747           0.808919   \n",
       "\n",
       "   MinEStateIndex       qed       SPS     MolWt  HeavyAtomMolWt  ExactMolWt  \\\n",
       "0        0.484550  0.378529  0.466241  0.205457        0.174775    0.206167   \n",
       "1        0.417018  0.713980  0.694891  0.371992        0.330948    0.373260   \n",
       "2        0.529035  0.417235  0.459854  0.273566        0.248858    0.272784   \n",
       "3        0.439730  0.619348  0.650299  0.283215        0.241706    0.284191   \n",
       "4        0.486395  0.480844  0.000000  0.246201        0.211988    0.247030   \n",
       "\n",
       "   ...  fr_amide  fr_aniline  fr_aryl_methyl  fr_benzene  fr_ester  fr_ether  \\\n",
       "0  ...       0.0         0.0             0.0    0.000000       0.0       0.0   \n",
       "1  ...       0.0         0.0             0.0    0.178966       0.0       0.0   \n",
       "2  ...       0.0         0.0             0.0    0.000000       0.0       0.0   \n",
       "3  ...       0.0         0.0             0.0    0.000000       0.0       0.0   \n",
       "4  ...       0.0         0.0             0.0    0.000000       0.0       0.0   \n",
       "\n",
       "   fr_halogen  fr_methoxy  fr_para_hydroxylation  fr_unbrch_alkane  \n",
       "0    0.000000         0.0                    0.0          0.026083  \n",
       "1    0.000000         0.0                    0.0          0.000000  \n",
       "2    0.178966         0.0                    0.0          0.000000  \n",
       "3    0.000000         0.0                    0.0          0.000000  \n",
       "4    0.000000         0.0                    0.0          0.000000  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the DataFrame\n",
    "normalized_data = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "df = pd.DataFrame(normalized_data, columns=df.columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of data: (442, 132)\n",
      "Removed 8 features with variance <= 0.01\n",
      "Removed 25 highly correlated features with correlation > 0.9\n",
      "Final shape of data: (442, 99)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Irritation</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>FpDensityMorgan1</th>\n",
       "      <th>FpDensityMorgan2</th>\n",
       "      <th>AvgIpc</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_allylic_oxid</th>\n",
       "      <th>fr_amide</th>\n",
       "      <th>fr_aniline</th>\n",
       "      <th>fr_aryl_methyl</th>\n",
       "      <th>fr_ester</th>\n",
       "      <th>fr_ether</th>\n",
       "      <th>fr_halogen</th>\n",
       "      <th>fr_methoxy</th>\n",
       "      <th>fr_para_hydroxylation</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648191</td>\n",
       "      <td>0.790665</td>\n",
       "      <td>0.484550</td>\n",
       "      <td>0.378529</td>\n",
       "      <td>0.466241</td>\n",
       "      <td>0.205457</td>\n",
       "      <td>0.546053</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.488390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.699113</td>\n",
       "      <td>0.122491</td>\n",
       "      <td>0.417018</td>\n",
       "      <td>0.713980</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.371992</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>0.657471</td>\n",
       "      <td>0.585415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529035</td>\n",
       "      <td>0.417235</td>\n",
       "      <td>0.459854</td>\n",
       "      <td>0.273566</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.435879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572659</td>\n",
       "      <td>0.347211</td>\n",
       "      <td>0.439730</td>\n",
       "      <td>0.619348</td>\n",
       "      <td>0.650299</td>\n",
       "      <td>0.283215</td>\n",
       "      <td>0.614833</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.504577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263747</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.486395</td>\n",
       "      <td>0.480844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246201</td>\n",
       "      <td>0.818421</td>\n",
       "      <td>0.910345</td>\n",
       "      <td>0.508828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Irritation  MaxAbsEStateIndex  MinAbsEStateIndex  MinEStateIndex       qed  \\\n",
       "0         1.0           0.648191           0.790665        0.484550  0.378529   \n",
       "1         1.0           0.699113           0.122491        0.417018  0.713980   \n",
       "2         1.0           0.000000           0.000000        0.529035  0.417235   \n",
       "3         1.0           0.572659           0.347211        0.439730  0.619348   \n",
       "4         1.0           0.263747           0.808919        0.486395  0.480844   \n",
       "\n",
       "        SPS     MolWt  FpDensityMorgan1  FpDensityMorgan2    AvgIpc  ...  \\\n",
       "0  0.466241  0.205457          0.546053          0.758621  0.488390  ...   \n",
       "1  0.694891  0.371992          0.515789          0.657471  0.585415  ...   \n",
       "2  0.459854  0.273566          0.596491          0.758621  0.435879  ...   \n",
       "3  0.650299  0.283215          0.614833          0.758621  0.504577  ...   \n",
       "4  0.000000  0.246201          0.818421          0.910345  0.508828  ...   \n",
       "\n",
       "   fr_allylic_oxid  fr_amide  fr_aniline  fr_aryl_methyl  fr_ester  fr_ether  \\\n",
       "0         0.000000       0.0         0.0             0.0       0.0       0.0   \n",
       "1         0.000000       0.0         0.0             0.0       0.0       0.0   \n",
       "2         0.000000       0.0         0.0             0.0       0.0       0.0   \n",
       "3         0.079749       0.0         0.0             0.0       0.0       0.0   \n",
       "4         0.000000       0.0         0.0             0.0       0.0       0.0   \n",
       "\n",
       "   fr_halogen  fr_methoxy  fr_para_hydroxylation  fr_unbrch_alkane  \n",
       "0    0.000000         0.0                    0.0          0.026083  \n",
       "1    0.000000         0.0                    0.0          0.000000  \n",
       "2    0.178966         0.0                    0.0          0.000000  \n",
       "3    0.000000         0.0                    0.0          0.000000  \n",
       "4    0.000000         0.0                    0.0          0.000000  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def feature_selection(df):\n",
    "    nonzero_thrd=0.01\n",
    "    cor_thrd=0.9\n",
    "    print(f\"Original shape of data: {df.shape}\")\n",
    "    \n",
    "    # Step 1: Remove features with low variance\n",
    "    nonzero_df = df.loc[:, df.var() > nonzero_thrd]\n",
    "    print(f\"Removed {df.shape[1] - nonzero_df.shape[1]} features with variance <= {nonzero_thrd}\")\n",
    "    \n",
    "    # Step 2: Remove highly correlated features\n",
    "    corr_matrix = nonzero_df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > cor_thrd)]\n",
    "    print(f\"Removed {len(to_drop)} highly correlated features with correlation > {cor_thrd}\")\n",
    "    \n",
    "    # Step 3: Return the cleaned dataset\n",
    "    cleaned_df = nonzero_df.drop(to_drop, axis=1)\n",
    "    print(f\"Final shape of data: {cleaned_df.shape}\")\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "df = feature_selection(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting class imbalance\n",
    "plt.figure(figsize=(8, 6))\n",
    "df['Irritation'].value_counts().plot(kind='bar', color=['blue', 'orange'])\n",
    "plt.title('Irritation Column')\n",
    "plt.xlabel('Irritation')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['No Irritation (0)', 'Irritation (1)'], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=['Irritation'])  # Assuming 'Call' is the target variable\n",
    "y = df['Irritation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (353, 98)\n",
      "Shape of X_test: (89, 98)\n",
      "Shape of y_train: (353,)\n",
      "Shape of y_test: (89,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232    0.0\n",
       "69     1.0\n",
       "306    0.0\n",
       "318    0.0\n",
       "270    0.0\n",
       "      ... \n",
       "5      1.0\n",
       "439    1.0\n",
       "113    1.0\n",
       "58     1.0\n",
       "49     1.0\n",
       "Name: Irritation, Length: 353, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print evaluation metrics and cross-validation results\n",
    "def print_score(y_train, y_pred_train, y_test, y_pred_test, grid_search=None, y_prob_test=None):\n",
    "    # Evaluate the model on training data\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Training Classification Report:\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    print(\"Training Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_train, y_pred_train))\n",
    "    print(\"\\n\")  # Separate training and testing output\n",
    "    \n",
    "    # Evaluate the model on testing data\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    print(\"Testing Accuracy:\", test_accuracy)\n",
    "    print(\"Testing Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print(\"Testing Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "    print(f\"ROC-AUC Score on Test Set: {roc_auc:.4f}\")\n",
    "        \n",
    "    # If GridSearchCV was used, print cross-validation results\n",
    "    if grid_search:\n",
    "        print(\"\\nGridSearchCV Summary:\")\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def print_score(y_train, y_pred_train, y_test, y_pred_test):    \n",
    "    # Evaluate the model on testing data\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    test_precision = precision_score(y_test, y_pred_test)\n",
    "    test_recall = recall_score(y_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Print Testing results\n",
    "    print(\"\\nTesting Results:\")\n",
    "    print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision: {test_precision:.4f}\")\n",
    "    print(f\"Recall: {test_recall:.4f}\")\n",
    "    print(f\"F1-Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost(X_train, X_test, y_train, y_test):\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.05],  # Lower learning rate\n",
    "        'max_depth': [3],  # Shallower trees\n",
    "        'n_estimators': [100, 150],  # More boosting rounds\n",
    "        'min_child_weight': [4, 5],  # Higher value to reduce overfitting\n",
    "        'subsample': [0.5, 0.6],  # Lower subsampling\n",
    "        'colsample_bytree': [0.5, 0.6],  # Fewer features per tree\n",
    "        'reg_alpha': [0.5, 1.0],  # Stronger L1 regularization\n",
    "        'reg_lambda': [2.0, 3.0],  # Stronger L2 regularization\n",
    "    }\n",
    "\n",
    "    # Create an instance of the XGBClassifier\n",
    "    final_model = xgb.XGBClassifier()\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "    ## Use early stopping with the best parameters\n",
    "    final_model = xgb.XGBClassifier(\n",
    "        **best_params, \n",
    "        early_stopping_rounds=10,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "        \"\"\"\n",
    "    # Fit the model using a validation set for early stopping\n",
    "    final_model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set=[(X_test, y_test)], \n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_test = final_model.predict(X_test)\n",
    "    y_pred_train = final_model.predict(X_train)\n",
    "\n",
    "    # Get predicted probabilities\n",
    "    y_prob_test = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    #print_score(y_train, y_pred_train, y_test, y_pred_test, grid_search, y_prob_test)\n",
    "    print_score(y_train, y_pred_train, y_test, y_pred_test)\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Results:\n",
      "Accuracy: 0.8315\n",
      "Precision: 0.8696\n",
      "Recall: 0.8163\n",
      "F1-Score: 0.8421\n"
     ]
    }
   ],
   "source": [
    "model = xgboost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(features, model):\n",
    "    # Create SHAP explainer\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    vals = np.abs(shap_values).mean(0)\n",
    "    feature_importance = pd.DataFrame(list(zip(X_train.columns, vals)), columns=['col_name', 'feature_importance_vals'])\n",
    "    feature_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n",
    "\n",
    "    # Extract top important features\n",
    "    top_features = feature_importance['col_name'].head(features).tolist()\n",
    "\n",
    "    # Filter training and validation data to include only top important features\n",
    "    X_train_selected = X_train[top_features]\n",
    "    X_test_selected = X_test[top_features]\n",
    "    return X_train_selected, X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Results:\n",
      "Accuracy: 0.8427\n",
      "Precision: 0.8889\n",
      "Recall: 0.8163\n",
      "F1-Score: 0.8511\n"
     ]
    }
   ],
   "source": [
    "X_train_selected, X_test_selected = feature_selection(50, model)\n",
    "model = xgboost(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X100 = shap.utils.sample(X, 100)\n",
    "sample_ind = 20\n",
    "explainer_xgb = shap.Explainer(model, X100)\n",
    "shap_values_xgb = explainer_xgb(X)\n",
    "shap.plots.waterfall(shap_values_xgb[sample_ind], max_display=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#absolutna hodnota aj kladnej aj zapornej\n",
    "shap.plots.bar(shap_values_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kladne iba\n",
    "shap.plots.bar(shap_values_xgb.abs.max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribucia pre zložitejšie prípady \n",
    "shap.plots.beeswarm(shap_values_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(shap_values_xgb[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### order descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_descriptors(shap_values, df):\n",
    "    # Convert SHAP values to absolute values and calculate mean\n",
    "    abs_shap_values = np.abs(shap_values)\n",
    "    mean_abs_shap_values = np.mean(abs_shap_values, axis=0)\n",
    "\n",
    "    # Get column names from df\n",
    "    column_names = df.columns\n",
    "\n",
    "    # Calculate mean importance across all samples\n",
    "    mean_importance = np.mean(mean_abs_shap_values, axis=0)\n",
    "\n",
    "    # Combine feature names with mean SHAP values\n",
    "    feature_importance_df = pd.DataFrame({'Feature': column_names, 'Mean_Shap_Value': mean_importance})\n",
    "\n",
    "    # Sort features by mean importance in descending order\n",
    "    sorted_features = feature_importance_df.sort_values(by='Mean_Shap_Value', ascending=False)\n",
    "\n",
    "\n",
    "    return  sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(features, model):\n",
    "    # Create SHAP explainer\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    shap_values = np.swapaxes(np.swapaxes(shap_values, 0, 2), 1, 2)\n",
    "\n",
    "    sorted_features = order_descriptors(shap_values, X_train)\n",
    "    print(sorted_features.head(features))\n",
    "\n",
    "    top_features = sorted_features[\"Feature\"].head(features).tolist()\n",
    "\n",
    "    X_train_selected =  X_train[top_features]\n",
    "    X_test_selected = X_test[top_features]\n",
    "\n",
    "    return X_train_selected, X_test_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    param_grid = {\n",
    "    'n_estimators': [100, 150, 200], # Viac stromov môže pomôcť, ale nie príliš veľa\n",
    "    'max_depth': [5, 8, 10], # Menšie hĺbky stromov\n",
    "    'min_samples_split': [10, 15, 20], # Väčšie minimálne vzorky na rozdelenie\n",
    "    'min_samples_leaf': [10, 15], # Väčšie listy\n",
    "    'max_features': ['sqrt', 'log2'], # Obmedzenie vlastností\n",
    "    'class_weight': ['balanced', 'balanced_subsample'], # Vyváženie tried\n",
    "    }\t\n",
    "\n",
    "\n",
    "    # Create a random forest classifier\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    \n",
    "    # Define cross-validation strategy\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Instantiate the grid search with cross-validation\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=cv, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "\n",
    "    # Perform grid search to find the best hyperparameters\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(f\"Best Cross-Validation ROC-AUC Score: {grid_search.best_score_:.4f}\")\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "    # Use the best model to make predictions on the test set\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Perform predictions on the training dataset\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    y_prob_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print_score(y_train, y_pred_train, y_test, y_pred_test, grid_search, y_prob_test)\n",
    "\n",
    "    \n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Cross-Validation ROC-AUC Score: 0.8243\n",
      "Best parameters found: {'class_weight': 'balanced', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Training Accuracy: 0.8895184135977338\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89       175\n",
      "         1.0       0.89      0.89      0.89       178\n",
      "\n",
      "    accuracy                           0.89       353\n",
      "   macro avg       0.89      0.89      0.89       353\n",
      "weighted avg       0.89      0.89      0.89       353\n",
      "\n",
      "Training Confusion Matrix:\n",
      "[[156  19]\n",
      " [ 20 158]]\n",
      "\n",
      "\n",
      "Testing Accuracy: 0.797752808988764\n",
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.79      0.79        43\n",
      "         1.0       0.80      0.80      0.80        46\n",
      "\n",
      "    accuracy                           0.80        89\n",
      "   macro avg       0.80      0.80      0.80        89\n",
      "weighted avg       0.80      0.80      0.80        89\n",
      "\n",
      "Testing Confusion Matrix:\n",
      "[[34  9]\n",
      " [ 9 37]]\n",
      "ROC-AUC Score on Test Set: 0.8569\n",
      "\n",
      "GridSearchCV Summary:\n",
      "Best Parameters: {'class_weight': 'balanced', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Best Cross-Validation Score: 0.8243\n"
     ]
    }
   ],
   "source": [
    "model = random_forest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected, X_test_selected = feature_selection(40, model)\n",
    "model = random_forest(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train_selected)\n",
    "print(shap_values.shape)\n",
    "print(X_train_selected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,1], X_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[index,:,1], base_values=explainer.expected_value[1], data=X_test.iloc[index,:]), max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[1], shap_values[index,:,1], feature_names=X_train_selected.columns, matplotlib=True, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accessing the first decision tree\n",
    "first_tree = model.estimators_[0]  \n",
    "\n",
    "# Adjusting the figure size\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "# Plotting the entire tree\n",
    "plot_tree(first_tree, feature_names=model.feature_names_in_, filled=True)\n",
    "\n",
    "# Saving the tree visualization to an image file\n",
    "plt.savefig('decision_tree.png')\n",
    "\n",
    "# Displaying the tree visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train, X_test, y_train, y_test):\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [3, 5, 7],  # Limit depth to prevent excessive splits\n",
    "        'min_samples_split': [10, 20],  # Larger splits ensure broader groupings\n",
    "        'min_samples_leaf': [5, 10],  # Increase minimum leaf size to reduce complexity\n",
    "        'max_features': ['sqrt', 'log2'],  # Limit features considered for each split\n",
    "        'min_impurity_decrease': [0.01, 0.05],  # Ensure meaningful splits\n",
    "        'class_weight': [None, 'balanced']  # Option to handle class imbalance\n",
    "    }\n",
    "    # Vytvorenie Decision Tree Classifier\n",
    "    dt = DecisionTreeClassifier()\n",
    "\n",
    "    # Definícia stratifikovaného k-fold krížového overovania\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    # Inicializácia grid search s krížovým overovaním\n",
    "    grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=cv, n_jobs=-1, verbose=0)\n",
    "\n",
    "    # Spustenie grid search pre hľadanie najlepších hyperparametrov\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Získanie najlepších hyperparametrov a skóre\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best parameters found:\", best_params)\n",
    "\n",
    "    # Použitie najlepšieho modelu na predikcie\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predikcie na trénovacej množine\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "    # Predikcie na testovacej množine\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "    # Get predicted probabilities\n",
    "    y_prob_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print_score(y_train, y_pred_train, y_test, y_pred_test, grid_search, y_prob_test)\n",
    "\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = decision_tree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected, X_test_selected = feature_selection(40, model)\n",
    "model = decision_tree(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_feature_selection(model):\n",
    "    background_summary = shap.sample(X_train, 100)\n",
    "    explainer = shap.KernelExplainer(model.predict_proba, background_summary)\n",
    "\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    shap_values = np.swapaxes(np.swapaxes(shap_values, 0, 2), 1, 2)\n",
    "    #shap.summary_plot(shap_values, X_train)\n",
    "\n",
    "    \n",
    "\n",
    "    sorted_features = order_descriptors(shap_values, X_train)\n",
    "    return sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(num_features, sorted_features):\n",
    "    print(sorted_features.head(num_features))\n",
    "\n",
    "    top_features = sorted_features[\"Feature\"].head(num_features).tolist()\n",
    "\n",
    "    X_train_selected =  X_train[top_features]\n",
    "    X_test_selected = X_test[top_features]\n",
    "\n",
    "    return X_train_selected, X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_knn_grid(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    # Create a pipeline with KernelPCA and kNN\n",
    "    pipeline = Pipeline([\n",
    "        ('kpca', KernelPCA(n_jobs=-1)),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ])\n",
    "    \n",
    "    # Define the parameter grid for kernels and kNN\n",
    "    param_grid = {\n",
    "        'kpca__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Test different kernels\n",
    "        'kpca__degree': [2, 3, 4],  # Degree for 'poly' kernel\n",
    "        'kpca__gamma': [0.1, 0.5, 1, 2],  # Gamma for 'rbf', 'poly', 'sigmoid'\n",
    "        'kpca__coef0': [0, 1],  # Coef0 for 'poly', 'sigmoid'\n",
    "        'knn__n_neighbors': [4, 5, 7, 9, 11, 14]  # Number of neighbors\n",
    "    }\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Output best parameters and score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    print(\"Best parameters found:\", best_params)\n",
    "\n",
    "    # Make predictions using the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    \"\"\"\n",
    "    best_model = KNeighborsClassifier()\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    y_prob_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    #print_score(y_train, y_pred_train, y_test, y_pred_test, grid_search, y_prob_test)\n",
    "    print_score(y_train, y_pred_train, y_test, y_pred_test)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Results:\n",
      "Accuracy: 0.8315\n",
      "Precision: 0.8269\n",
      "Recall: 0.8776\n",
      "F1-Score: 0.8515\n"
     ]
    }
   ],
   "source": [
    "model = kernel_knn_grid(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81eb43d7539c4209a899621a381ecdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_features = kernel_feature_selection(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected, X_test_selected = get_features(9, sorted_features) \n",
    "model = knn(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_summary = shap.sample(X_train_selected, 100)\n",
    "explainer = shap.KernelExplainer(model.predict_proba, background_summary)\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,1], X_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[index,:,1], base_values=explainer.expected_value[1], data=X_test.iloc[index,:]), max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[1], shap_values[index,:,1], feature_names=X_train_selected.columns, matplotlib=True, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X_train, X_test, y_train, y_test):\n",
    "    # Define the parameter distribution with lower regularization\n",
    "    param_dist = {\n",
    "        'C': uniform(loc=0.1, scale=1),  # Decrease range for C to focus on simpler models\n",
    "        'gamma': uniform(loc=0.001, scale=0.02)  # Lower gamma to reduce complexity\n",
    "    }\n",
    "\n",
    "    # Create SVM classifier with RBF kernel and balanced class weights\n",
    "    svm_model = SVC(kernel='rbf', probability=True, class_weight='balanced')\n",
    "\n",
    "    # Cross-validation strategy (StratifiedKFold)\n",
    "    cv = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)\n",
    "\n",
    "    # RandomizedSearchCV to search hyperparameter space\n",
    "    random_search = RandomizedSearchCV(estimator=svm_model, param_distributions=param_dist, \n",
    "                                       n_iter=200, cv=cv, n_jobs=-1, verbose=1, random_state=42)\n",
    "\n",
    "    # Fit the randomized search to training data\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters and training score\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "    print(\"Best parameters found:\", best_params)\n",
    "    print(\"Best training score:\", best_score)\n",
    "\n",
    "    # Use the best model to make predictions\n",
    "    best_svm_model = random_search.best_estimator_\n",
    "    y_pred_train = best_svm_model.predict(X_train)\n",
    "    y_pred_test = best_svm_model.predict(X_test)\n",
    "\n",
    "    # Get predicted probabilities for ROC curve\n",
    "    y_prob_test = best_svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Print scores and evaluation metrics\n",
    "    print_score(y_train, y_pred_train, y_test, y_pred_test, random_search, y_prob_test)\n",
    "\n",
    "    return best_svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features = kernel_feature_selection(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected, X_test_selected = get_features(5, sorted_features) \n",
    "model = svm(X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_summary = shap.sample(X_train_selected, 25)\n",
    "explainer = shap.KernelExplainer(model.predict_proba, background_summary)\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,1], X_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[index,:,1], base_values=explainer.expected_value[1], data=X_test.iloc[index,:]), max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[1], shap_values[index,:,1], feature_names=X_train_selected.columns, matplotlib=True, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input SMILES string\n",
    "smiles = \"CCCCCCCCOC(=O)c1cc(Br)cc(C#N)c1Br\"  # Replace with your SMILES string\n",
    "\n",
    "# Convert SMILES to a molecule object\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "# Prepare the molecule for drawing\n",
    "Chem.rdDepictor.Compute2DCoords(mol)\n",
    "\n",
    "# Set up atom contributions for highlighting (example values, modify as needed)\n",
    "highlight_atoms = [0, 1, 2, 3, 8, 10]\n",
    "highlight_colors = {0: (1.0, 0.5, 0.5), 1: (1.0, 0.8, 0.8), 8: (0.5, 0.9, 0.5)}\n",
    "\n",
    "# Create a drawing object\n",
    "drawer = rdMolDraw2D.MolDraw2DSVG(500, 300)  # SVG rendering for Jupyter\n",
    "drawer.drawOptions().highlightColour = (0.8, 0.3, 0.3)  # Default highlight color\n",
    "drawer.DrawMolecule(\n",
    "    mol, highlightAtoms=highlight_atoms, highlightAtomColors=highlight_colors\n",
    ")\n",
    "drawer.FinishDrawing()\n",
    "\n",
    "# Render SVG directly in Jupyter\n",
    "svg = drawer.GetDrawingText()\n",
    "display(SVG(svg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.best_model = None\n",
    "        self.param_grid = {\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3],\n",
    "            'n_estimators': [100, 150],\n",
    "            'min_child_weight': [4, 5],\n",
    "            'subsample': [0.5, 0.6],\n",
    "            'colsample_bytree': [0.5, 0.6],\n",
    "            'reg_alpha': [0.5, 1.0],\n",
    "            'reg_lambda': [2.0, 3.0],\n",
    "        }\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        model = xgb.XGBClassifier()\n",
    "        \n",
    "        # GridSearchCV with cross-validation to find the best hyperparameters\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=self.param_grid, scoring='accuracy', cv=5)\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"Best parameters found: {best_params}\")\n",
    "        \n",
    "        # Fit the final model with early stopping\n",
    "        self.best_model = xgb.XGBClassifier(**best_params, early_stopping_rounds=10, eval_metric=\"logloss\")\n",
    "        self.best_model.fit(X, y, eval_set=[(X, y)], verbose=False)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.best_model is None:\n",
    "            raise Exception(\"Model is not fitted yet\")\n",
    "        return self.best_model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if self.best_model is None:\n",
    "            raise Exception(\"Model is not fitted yet\")\n",
    "        return self.best_model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file_path)\n",
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=['Irritation'])  # Assuming 'Call' is the target variable\n",
    "y = df['Irritation']\n",
    "\n",
    "y = y.replace({'I': 1, 'NI': 0})\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping functions inside FunctionTransformer correctly\n",
    "descriptor_transformer = FunctionTransformer(lambda df: calculate_descriptors(df), validate=False)\n",
    "drop_transformer = FunctionTransformer(lambda df: drop_columns(df), validate=False)\n",
    "#fingerprint_transformer = FunctionTransformer(lambda df: calculate_fingerprint(df), validate=False)\n",
    "outliers_transformer = FunctionTransformer(lambda df: detect_outliers(df), validate=False)\n",
    "feature_selection_t = FunctionTransformer(lambda df: feature_selection(df), validate=False)\n",
    "scaler = MinMaxScaler()\n",
    "label_encoder = LabelEncoder()\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with the transformers\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('descriptor_transformer', descriptor_transformer),\n",
    "    #('fingerprint_transformer', fingerprint_transformer),\n",
    "    ('drop_transformer', drop_transformer),\n",
    "    ('imputer', imputer),\n",
    "    ('outliers_transformer', outliers_transformer),\n",
    "    ('feature_selection', feature_selection_t),\n",
    "    ('scaler', scaler),\n",
    "    ('classifier', XGBoostWrapper())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pipeline.predict(X_train)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Make predictions on the training set using the fitted pipeline\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "\n",
    "# Get predicted probabilities for the test set (this uses the pipeline's classifier)\n",
    "y_prob_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Print the evaluation scores\n",
    "print_score(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
